import streamlit as st
from langchain.prompts import FewShotPromptTemplate, PromptTemplate
from langchain.llms import OpenAI
from langchain.output_parsers import StructuredOutputParser, ResponseSchema
import os

# OpenAI í‚¤ëŠ” os.environ["OPENAI_API_KEY"]ë¡œ Colab ì™¸ë¶€ì—ì„œ ë“±ë¡í–ˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
llm = OpenAI(temperature=0.7)

# Few-shot ì˜ˆì œ
examples = [
    {"role": "ê°œë°œì", "question": "í˜‘ì—… ì¤‘ ë¬¸ì œ í•´ê²° ê²½í—˜?", "answer": "Git ì¶©ëŒ í•´ê²°í•˜ë©° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ê°œì„ "},
    {"role": "UX ë””ìì´ë„ˆ", "question": "ì‚¬ìš©ì í”¼ë“œë°± ê°œì„  ì‚¬ë¡€?", "answer": "ë¡œê·¸ì¸ ë²„íŠ¼ ìœ„ì¹˜ ë³€ê²½ìœ¼ë¡œ ì´íƒˆë¥  ê°ì†Œ"},
    {"role": "ê¸°íšì", "question": "ì¼ì • ì§€ì—° ëŒ€ì²˜ ê²½í—˜?", "answer": "ë²”ìœ„ ì¡°ì •ê³¼ ì™¸ì£¼ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ìœ¼ë¡œ ì¼ì • ë§ì¶¤"},
]

example_prompt = PromptTemplate(
    input_variables=["role", "question", "answer"],
    template="ì§ë¬´: {role}\nì§ˆë¬¸: {question}\në‹µë³€: {answer}\n"
)

prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
    suffix="ì§ë¬´: {input_role}\nì§ˆë¬¸:",
    input_variables=["input_role"]
)

response_schemas = [
    ResponseSchema(name="question", description="ë©´ì ‘ ì§ˆë¬¸"),
    ResponseSchema(name="answer", description="ë©´ì ‘ ë‹µë³€"),
]
output_parser = StructuredOutputParser.from_response_schemas(response_schemas)

def generate_interview_qa(role):
    full_prompt = prompt.format(input_role=role) + "\n" + output_parser.get_format_instructions()
    response = llm(full_prompt)
    return output_parser.parse(response)

# --------- UI ê¾¸ë¯¸ê¸° ---------

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AI ë©´ì ‘ ìƒì„±ê¸°", page_icon="ğŸ¤", layout="centered")

# ì œëª© & ì„¤ëª…
st.markdown("<h1 style='text-align:center; color:#4CAF50;'>ğŸ¤ AI ë©´ì ‘ ì§ˆë¬¸/ë‹µë³€ ìƒì„±ê¸°</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center;'>ì§ë¬´ì— ë§ëŠ” ì¸í„°ë·° ì§ˆë¬¸ê³¼ ë‹µë³€ì„ AIê°€ ìë™ìœ¼ë¡œ ìƒì„±í•´ë“œë¦½ë‹ˆë‹¤.</p>", unsafe_allow_html=True)
st.markdown("---")

# ì„ íƒ ì˜µì…˜
role_color = {
    "ê°œë°œì": "#2196F3",
    "UX ë””ìì´ë„ˆ": "#9C27B0",
    "ê¸°íšì": "#4CAF50"
}

job_roles = ["ê°œë°œì", "UX ë””ìì´ë„ˆ", "ê¸°íšì"]
selected_role = st.selectbox("ğŸ§‘â€ğŸ’¼ ì§ë¬´ë¥¼ ì„ íƒí•˜ì„¸ìš”", job_roles)

# ìƒì„± ë²„íŠ¼
if st.button("âœ¨ ì§ˆë¬¸/ë‹µë³€ ìƒì„±í•˜ê¸°"):
    with st.spinner("AIê°€ ì—´ì‹¬íˆ ê³ ë¯¼ ì¤‘ì…ë‹ˆë‹¤..."):
        result = generate_interview_qa(selected_role)

        # ê²°ê³¼ ì¶œë ¥
        st.markdown("---")
        st.markdown(
            f"<div style='background-color:{role_color[selected_role]}; padding:20px; border-radius:10px;'>"
            f"<h3 style='color:white;'>ğŸ“ ì§ˆë¬¸</h3>"
            f"<p style='color:white; font-size:18px;'>{result['question']}</p>"
            f"</div>",
            unsafe_allow_html=True
        )
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown(
            f"<div style='background-color:#eeeeee; padding:20px; border-radius:10px;'>"
            f"<h3>ğŸ’¬ ë‹µë³€</h3>"
            f"<p style='font-size:18px;'>{result['answer']}</p>"
            f"</div>",
            unsafe_allow_html=True
        )
